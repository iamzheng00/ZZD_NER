{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoding=utf-8\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow_addons.text import crf\n",
    "\n",
    "class myModel(keras.Model):\n",
    "    def __init__(self,time_steps,batch_size):\n",
    "        super(myModel,self).__init__()\n",
    "        self.time_steps = time_steps\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.fw_LSTM = layers.LSTM(units=100,activation='relu',return_sequences=True,go_backwards=False)\n",
    "        self.bw_LSTM = layers.LSTM(units=100,activation='relu',return_sequences=True,go_backwards=True)\n",
    "        self.BiLSTM = layers.Bidirectional(self.fw_LSTM,backward_layer=self.bw_LSTM,input_shape=(self.batch_size, self.time_steps)) #todo\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x = self.BiLSTM(inputs)\n",
    "        return x\n",
    "\n",
    "    def embedding_layer(self):\n",
    "        pass # todo\n",
    "\n",
    "batch_size = 2\n",
    "time_steps = 5\n",
    "\n",
    "x1 = np.array([[1,2,3,4,5],[3,1,5,2,1],[3,4,5,0,2],[5,3,4,0,1]],dtype='int32')\n",
    "y1 = np.array([[0,0,1,2,3],\n",
    "               [1,0,0,0,0],\n",
    "               [1,2,3,0,0],\n",
    "               [0,1,2,0,0]],dtype='int32')\n",
    "lens = np.array([5,5,5,5])\n",
    "model = myModel(batch_size,time_steps)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tf.Tensor(\n",
      "[[2 0 1 0 1]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 0]], shape=(4, 5), dtype=int32)\n",
      "Epoch 1, train acc: 0.0\n",
      "Epoch 2, train acc: 0.0\n",
      "Epoch 3, train acc: 0.0\n",
      "Epoch 4, train acc: 0.0\n",
      "Epoch 5, train acc: 0.0\n",
      "Epoch 6, train acc: 0.0\n",
      "Epoch 7, train acc: 0.0\n",
      "Epoch 8, train acc: 0.0\n",
      "Epoch 9, train acc: 0.0\n",
      "Epoch 10, train acc: 0.0\n",
      "10\n",
      "tf.Tensor(\n",
      "[[2 3 2 3 2]\n",
      " [2 3 2 3 2]\n",
      " [2 3 2 3 2]\n",
      " [2 3 2 3 2]], shape=(4, 5), dtype=int32)\n",
      "Epoch 11, train acc: 0.0\n",
      "Epoch 12, train acc: 0.0\n",
      "Epoch 13, train acc: 0.0\n",
      "Epoch 14, train acc: 0.0\n",
      "Epoch 15, train acc: 0.0\n",
      "Epoch 16, train acc: 25.0\n",
      "Epoch 17, train acc: 25.0\n",
      "Epoch 18, train acc: 25.0\n",
      "Epoch 19, train acc: 25.0\n",
      "Epoch 20, train acc: 25.0\n",
      "20\n",
      "tf.Tensor(\n",
      "[[2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]], shape=(4, 5), dtype=int32)\n",
      "Epoch 21, train acc: 25.0\n",
      "Epoch 22, train acc: 25.0\n",
      "Epoch 23, train acc: 25.0\n",
      "Epoch 24, train acc: 25.0\n",
      "Epoch 25, train acc: 25.0\n",
      "Epoch 26, train acc: 25.0\n",
      "Epoch 27, train acc: 25.0\n",
      "Epoch 28, train acc: 25.0\n",
      "Epoch 29, train acc: 25.0\n",
      "Epoch 30, train acc: 25.0\n",
      "30\n",
      "tf.Tensor(\n",
      "[[2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]], shape=(4, 5), dtype=int32)\n",
      "Epoch 31, train acc: 25.0\n",
      "Epoch 32, train acc: 25.0\n",
      "Epoch 33, train acc: 25.0\n",
      "Epoch 34, train acc: 25.0\n",
      "Epoch 35, train acc: 25.0\n",
      "Epoch 36, train acc: 25.0\n",
      "Epoch 37, train acc: 25.0\n",
      "Epoch 38, train acc: 25.0\n",
      "Epoch 39, train acc: 25.0\n",
      "Epoch 40, train acc: 25.0\n",
      "40\n",
      "tf.Tensor(\n",
      "[[2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]], shape=(4, 5), dtype=int32)\n",
      "Epoch 41, train acc: 25.0\n",
      "Epoch 42, train acc: 25.0\n",
      "Epoch 43, train acc: 25.0\n",
      "Epoch 44, train acc: 25.0\n",
      "Epoch 45, train acc: 25.0\n",
      "Epoch 46, train acc: 25.0\n",
      "Epoch 47, train acc: 25.0\n",
      "Epoch 48, train acc: 25.0\n",
      "Epoch 49, train acc: 25.0\n",
      "Epoch 50, train acc: 25.0\n"
     ]
    }
   ],
   "source": [
    "LSTM_dim = 50\n",
    "tag_num = 4\n",
    "fw_LSTM = layers.LSTM(units=LSTM_dim,return_sequences=True,go_backwards=False)\n",
    "bw_LSTM = layers.LSTM(units=LSTM_dim,return_sequences=True,go_backwards=True)\n",
    "# BiLSTM = layers.Bidirectional(fw_LSTM,backward_layer=bw_LSTM,input_shape=(4, 5)) #todo\n",
    "BiLSTM = layers.Bidirectional(fw_LSTM,backward_layer=bw_LSTM) #todo\n",
    "\n",
    "# x3 = tf.random.normal((2,5,1))\n",
    "# x3\n",
    "# x = BiLSTM(x)\n",
    "if tf.test.is_gpu_available():\n",
    "  with tf.device(\"/gpu:0\"):\n",
    "    train_loss = keras.metrics.Mean(name='train_loss')\n",
    "    train_acc = keras.metrics.CategoricalAccuracy(name='train_acc')\n",
    "\n",
    "\n",
    "    initializer = tf.keras.initializers.GlorotUniform()\n",
    "    trans_p = tf.Variable(initializer([tag_num, tag_num]), trainable=True, name=\"transitions\")\n",
    "\n",
    "    w_init = tf.random_normal_initializer()\n",
    "    w_proj = tf.Variable(w_init([100,tag_num]),trainable=True)\n",
    "    b_init = tf.zeros_initializer()\n",
    "    b_proj = tf.Variable(b_init([tag_num]),trainable=True)\n",
    "    proj_layer = layers.Dense(tag_num)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "    for epoch in range(0,50):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # x = tf.keras.layers.Embedding(6, 1, mask_zero=True)(x1)\n",
    "            x = tf.expand_dims(x1,axis=-1)\n",
    "            x = tf.cast(x,dtype='float')\n",
    "            x = BiLSTM(x)\n",
    "            # 全连接映射层\n",
    "            pred = proj_layer(x)\n",
    "            # pred = tf.matmul(x,w_proj) + b_proj\n",
    "            # print(pred)\n",
    "\n",
    "            # crf\n",
    "            loss, trans_p = crf.crf_log_likelihood(inputs=pred,tag_indices=y1,transition_params=trans_p,sequence_lengths=lens)\n",
    "            loss = tf.reduce_sum(loss)\n",
    "            seq_tags, best_score = crf.crf_decode(potentials=pred,transition_params=trans_p, sequence_length=lens)\n",
    "            # print(trans_p.shape)\n",
    "        if epoch%10==0:\n",
    "            print(epoch)\n",
    "            print(seq_tags)\n",
    "            # print(trans_p)\n",
    "            # print(BiLSTM.trainable_variables[0][1])\n",
    "\n",
    "        grads = tape.gradient(loss,[BiLSTM.trainable_variables,trans_p])\n",
    "        grads2 = tape.gradient(loss,proj_layer.trainable_variables)\n",
    "        # grads_crf = tape.gradient(loss,trans_p)\n",
    "        grads_and_vars_clip0 = [[tf.clip_by_value(g, -5, 5), v] for g, v in zip(grads[0], BiLSTM.trainable_variables)]\n",
    "        grads_and_vars_clip1 = [[tf.clip_by_value(g, -5, 5), v] for g, v in zip([grads[1]], [trans_p])]\n",
    "\n",
    "        optimizer.apply_gradients(grads_and_vars_clip0)\n",
    "        optimizer.apply_gradients(grads_and_vars_clip1)\n",
    "        optimizer.apply_gradients(zip(grads2,proj_layer.trainable_variables))\n",
    "\n",
    "    # train_loss.reset_states()\n",
    "        train_acc.reset_states()\n",
    "    # train_loss(loss)\n",
    "        train_acc(y1,seq_tags)\n",
    "        template = 'Epoch {}, train acc: {}'\n",
    "        print (template.format(epoch+1,train_acc.result()*100))\n",
    "    #                        train_loss.result()))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_object = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "train_loss = keras.metrics.Mean(name='train_loss')\n",
    "train_acc = keras.metrics.SparseTopKCategoricalAccuracy(name='train_acc')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='test_acc')\n",
    "\n",
    "def train_step(input, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predict = model(input)\n",
    "        loss = loss_object(predict, y1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "[<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, <tf.Tensor: shape=(), dtype=float32, numpy=6.0>]\n"
     ]
    }
   ],
   "source": [
    "x=tf.constant(1.0)\n",
    "w=tf.constant(2.0)\n",
    "y=tf.Variable(1.0,trainable=True)\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(x)\n",
    "    z = w*y*y*y\n",
    "    func1 = x*z\n",
    "df_dx = tape.gradient(func1,x)\n",
    "dz_dy = tape.gradient(func1,y)\n",
    "grads = tape.gradient(func1,[x,y])\n",
    "print(df_dx)\n",
    "print(dz_dy)\n",
    "print(grads)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "635\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "path = r'F:\\zzd\\毕业论文\\论文代码\\DataSets\\2014人民日报\\vocab_test.pkl'\n",
    "with open(path, 'rb') as f:\n",
    "    word2id = pickle.load(f)\n",
    "print(type(word2id))\n",
    "print(word2id['你'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1 2 3]\n",
      "  [4 5 6]]], shape=(1, 2, 3), dtype=int32)\n",
      "[array([1, 2, 3, 4, 5, 6])]\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "l = [[[1,2,3],[4,5,6]]]\n",
    "p = tf.convert_to_tensor(l)\n",
    "print(p)\n",
    "s = np.array(p)\n",
    "l = s.flatten()\n",
    "lo = []\n",
    "lo.append(l)\n",
    "print(lo)\n",
    "for i in lo:\n",
    "    for l in i:\n",
    "        print(l)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number is 2.3563\n"
     ]
    }
   ],
   "source": [
    "l = 2.35625489154\n",
    "print('number is {:.4f}'.format(l))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1.0075055e-03 -3.7291273e-04]\n",
      "  [ 3.3740071e-04 -8.1955723e-04]\n",
      "  [-8.8838907e-04 -2.1940534e-04]\n",
      "  [-1.2661041e-03 -3.2285543e-04]\n",
      "  [ 8.8713696e-04  1.9003404e-05]]], shape=(1, 5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import time\n",
    "import os\n",
    "x = [[1,2,3,4,5]]\n",
    "y = [1,1,0,0,1]\n",
    "\n",
    "LSTM_dim = 100\n",
    "tag_num = 2\n",
    "# 模型所需的层定义\n",
    "embedding = layers.Embedding(input_dim=10000, output_dim=2, mask_zero=True)\n",
    "dense = layers.Dense(tag_num)\n",
    "# fw_LSTM = layers.LSTM(units=LSTM_dim, return_sequences=True, go_backwards=False)\n",
    "# bw_LSTM = layers.LSTM(units=LSTM_dim, return_sequences=True, go_backwards=True)\n",
    "# BiLSTM = layers.Bidirectional(fw_LSTM, backward_layer=bw_LSTM)\n",
    "BiLSTM = layers.Bidirectional(layers.LSTM(100,return_sequences=True))\n",
    "\n",
    "x = tf.convert_to_tensor(x,dtype='int32')\n",
    "z = embedding(x)\n",
    "z = BiLSTM(z)\n",
    "z = dense(z)\n",
    "print(z)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2 samples\n",
      "2/2 [==============================] - 4s 2s/sample - loss: 2.4692 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 5\n",
    "model = keras.Sequential([\n",
    "    layers.Embedding(vocab_size, embedding_dim),\n",
    "    # layers.GlobalAveragePooling1D(),\n",
    "    # layers.Dense(160, activation='relu'),\n",
    "    # layers.Dense(1, activation='sigmoid')\n",
    "    # layers.Dense(160, activation='relu'),\n",
    "    layers.Bidirectional(layers.LSTM(2,return_sequences=True)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "             loss=keras.losses.BinaryCrossentropy(),\n",
    "             metrics=['accuracy'])\n",
    "x = [[1,2,3,4,5],[5,4,3,2,1]]\n",
    "y = [1,0]\n",
    "history = model.fit(x, y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-d4890afa",
   "language": "python",
   "display_name": "PyCharm (TFtest)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}